{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "repo_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)\n",
    "\n",
    "print(f\"Repository Root: {repo_root}\")\n",
    "\n",
    "from dataloading.datasets import LadosDataset, StrantzaDataset\n",
    "from models.mit_b2 import MIT_B2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CHOICE = \"dataset1\"   #  \"dataset1\" or \"dataset2\"\n",
    "\n",
    "DATASET_MAP = {\n",
    "    \"dataset1\": {\n",
    "        \"name\": \"dataset1\",\n",
    "        \"class\": LadosDataset,\n",
    "        \"ckpt_imagenet\": \"Dataset1-FineTuned-ImageNet-Initialization\",\n",
    "        \"ckpt_synth\":   \"Dataset1-FineTuned-Synthetic-Pretrained\",\n",
    "    },\n",
    "    \"dataset2\": {\n",
    "        \"name\": \"dataset2\",\n",
    "        \"class\": StrantzaDataset,\n",
    "        \"ckpt_imagenet\": \"Dataset2-FineTuned-ImageNet-Initialization\",\n",
    "        \"ckpt_synth\":   \"Dataset2-FineTuned-Synthetic-Pretrained\",\n",
    "    }\n",
    "}\n",
    "\n",
    "cfg = DATASET_MAP[DATASET_CHOICE]\n",
    "print(\"Selected dataset:\", cfg[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def find_checkpoint(fragment, osf_project_id=None):\n",
    "    \"\"\"\n",
    "    Find checkpoint locally or download from OSF if not found.\n",
    "    \n",
    "    Args:\n",
    "        fragment: String fragment to match checkpoint filename\n",
    "    \"\"\"\n",
    "    ckpt_dir = os.path.join(repo_root, \"output\", \"checkpoints\")\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    \n",
    "    # First, try to find locally\n",
    "    ckpts = glob.glob(os.path.join(ckpt_dir, \"*\"))\n",
    "    found = [c for c in ckpts if fragment.lower() in os.path.basename(c).lower()]\n",
    "    \n",
    "    if found:\n",
    "        return max(found, key=os.path.getctime)\n",
    "    \n",
    "    # If not found locally and OSF project ID provided, try to download\n",
    "    if osf_project_id:\n",
    "        print(f\"ðŸ” Checkpoint not found locally. Attempting to download from OSF...\")\n",
    "        downloaded_path = download_from_osf(fragment, ckpt_dir, osf_project_id)\n",
    "        if downloaded_path:\n",
    "            return downloaded_path\n",
    "    \n",
    "    print(f\"No checkpoint matching: {fragment}\")\n",
    "    return None\n",
    "\n",
    "def download_from_osf(fragment, ckpt_dir, osf_project_id):\n",
    "    \"\"\"\n",
    "    Download checkpoint from OSF storage.\n",
    "    \n",
    "    Args:\n",
    "        fragment: Filename fragment to search for\n",
    "        ckpt_dir: Local directory to save checkpoint\n",
    "        osf_project_id: OSF project ID\n",
    "    \"\"\"\n",
    "    # OSF API endpoint to list files\n",
    "    api_url = f\"https://api.osf.io/v2/nodes/g364t/files/osfstorage/\"\n",
    "    \n",
    "    try:\n",
    "        # Get list of files in OSF project\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        files = response.json()['data']\n",
    "        \n",
    "        # Find matching file\n",
    "        matching_file = None\n",
    "        for file in files:\n",
    "            filename = file['attributes']['name']\n",
    "            if fragment.lower() in filename.lower() and filename.endswith('.ckpt'):\n",
    "                matching_file = file\n",
    "                break\n",
    "        \n",
    "        if not matching_file:\n",
    "            print(f\" No checkpoint matching '{fragment}' found on OSF\")\n",
    "            return None\n",
    "        \n",
    "        # Get download URL\n",
    "        download_url = matching_file['links']['download']\n",
    "        filename = matching_file['attributes']['name']\n",
    "        local_path = os.path.join(ckpt_dir, filename)\n",
    "        \n",
    "        print(f\"Downloading {filename}...\")\n",
    "        \n",
    "        # Download file with progress\n",
    "        response = requests.get(download_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        block_size = 8192\n",
    "        \n",
    "        with open(local_path, 'wb') as f:\n",
    "            downloaded = 0\n",
    "            for chunk in response.iter_content(chunk_size=block_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    downloaded += len(chunk)\n",
    "                    if total_size > 0:\n",
    "                        percent = (downloaded / total_size) * 100\n",
    "                        print(f\"\\râ¬‡ï¸  Progress: {percent:.1f}%\", end='')\n",
    "        \n",
    "        print(f\"\\nDownloaded: {filename}\")\n",
    "        return local_path\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading from OSF: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_model(ckpt_path):\n",
    "    model = MIT_B2.load_from_checkpoint(ckpt_path)\n",
    "    model.eval()\n",
    "    return model.to(device)\n",
    "\n",
    "def load_dataset(cfg):\n",
    "    data_dir = os.path.join(repo_root, \"data\", cfg[\"name\"])\n",
    "    return cfg[\"class\"](root_dir=data_dir, normalize_percentile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAMGenerator:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        self.hook_fwd = target_layer.register_forward_hook(self._save_act)\n",
    "        self.hook_bwd = target_layer.register_full_backward_hook(self._save_grad)\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        self.hook_fwd.remove()\n",
    "        self.hook_bwd.remove()\n",
    "\n",
    "    def _save_act(self, m, inp, out):\n",
    "        if isinstance(out, (tuple,list)): out = out[0]\n",
    "        self.activations = out\n",
    "\n",
    "    def _save_grad(self, m, gin, gout):\n",
    "        if isinstance(gout, (tuple,list)): gout = gout[0]\n",
    "        self.gradients = gout\n",
    "\n",
    "    def generate_cam(self, x):\n",
    "        self.model.zero_grad()\n",
    "        out = self.model(x)\n",
    "        score = (out[:,0] + out[:,1]).sum()\n",
    "        score.backward()\n",
    "\n",
    "        if self.gradients is None or self.activations is None:\n",
    "            B,C,H,W = x.shape\n",
    "            return torch.zeros((B,1,H//32,W//32), device=x.device)\n",
    "\n",
    "        w = torch.mean(self.gradients, dim=(2,3), keepdim=True)\n",
    "        cam = torch.sum(w * self.activations, dim=1, keepdim=True)\n",
    "        cam = F.relu(cam)\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        return cam.detach()\n",
    "\n",
    "\n",
    "class StressTester:\n",
    "    def __init__(self, model, device=\"cuda\"):\n",
    "        self.model = model.to(device).eval()\n",
    "        self.device = device\n",
    "\n",
    "        enc = model.encoder\n",
    "        if hasattr(enc, \"block4\"):\n",
    "            layer = enc.block4[-1]\n",
    "        else:\n",
    "            layer = list(enc.children())[-1]\n",
    "\n",
    "        print(f\"[{model.__class__.__name__}] Hooking Grad-CAM to: {layer}\")\n",
    "        self.gradcam = GradCAMGenerator(model, layer)\n",
    "\n",
    "    def cleanup(self):\n",
    "        self.gradcam.remove_hooks()\n",
    "\n",
    "    # ------------------------------\n",
    "    # Normalize Predictions\n",
    "    # ------------------------------\n",
    "    @torch.no_grad()\n",
    "    def _normalize(self, pred):\n",
    "        if torch.is_tensor(pred): pred = pred.cpu().numpy()\n",
    "        a, b = pred[:,0], pred[:,1]\n",
    "        d = a + b + 1e-8\n",
    "        return np.stack([a/d, b/d], axis=1)\n",
    "\n",
    "    # ------------------------------\n",
    "    # ZOOM TEST\n",
    "    # ------------------------------\n",
    "    @torch.no_grad()\n",
    "    def zoom_image(self, img, z):\n",
    "        if z == 1.0: return img\n",
    "        B,C,H,W = img.shape\n",
    "        ch, cw = int(H/z), int(W/z)\n",
    "        sh, sw = (H-ch)//2, (W-cw)//2\n",
    "        crop = img[:,:,sh:sh+ch, sw:sw+cw]\n",
    "        return F.interpolate(crop, (H,W), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    def run_zoom(self, img, factors=[1.0, 1.5, 2.0]):\n",
    "        img = img.to(self.device)\n",
    "        res = {\"factors\": factors, \"preds\": [], \"cams\": []}\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            base = self.gradcam.generate_cam(img)\n",
    "\n",
    "        for f in factors:\n",
    "            zm = self.zoom_image(img, f)\n",
    "            pred = self.model(zm)\n",
    "            res[\"preds\"].append(self._normalize(pred))\n",
    "            with torch.enable_grad():\n",
    "                cam = self.gradcam.generate_cam(zm)\n",
    "                cam = F.interpolate(cam, base.shape[2:], mode=\"bilinear\")\n",
    "                res[\"cams\"].append(cam.cpu())\n",
    "\n",
    "        res[\"base\"] = base.cpu()\n",
    "        return res\n",
    "\n",
    "    # ------------------------------\n",
    "    # RADIAL MASK TEST\n",
    "    # ------------------------------\n",
    "    @torch.no_grad()\n",
    "    def mask_center_radial(self, image, radius):\n",
    "        B, C, H, W = image.shape\n",
    "        y, x = torch.meshgrid(\n",
    "            torch.arange(H, device=image.device) - H//2,\n",
    "            torch.arange(W, device=image.device) - W//2,\n",
    "            indexing=\"ij\"\n",
    "        )\n",
    "        R = torch.sqrt(x**2 + y**2)\n",
    "        mask = (R >= radius).float()\n",
    "        return image * mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def run_radial(self, img, radii=[0, 200, 400, 600]):\n",
    "        img = img.to(self.device)\n",
    "        res = {\"radii\": radii, \"preds\": []}\n",
    "        for r in radii:\n",
    "            masked = self.mask_center_radial(img, r)\n",
    "            pred = self.model(masked)\n",
    "            res[\"preds\"].append(self._normalize(pred))\n",
    "        res[\"preds\"] = np.array(res[\"preds\"])\n",
    "        return res\n",
    "\n",
    "    # ------------------------------\n",
    "    # Visualization\n",
    "    # ------------------------------\n",
    "    def plot_zoom(self, img, res, title):\n",
    "        factors = res[\"factors\"]\n",
    "        cams = res[\"cams\"]\n",
    "        base = res[\"base\"]\n",
    "        preds = res[\"preds\"]\n",
    "\n",
    "        plt.figure(figsize=(4*len(factors),8))\n",
    "        for i,f in enumerate(factors):\n",
    "            cam = cams[i].squeeze().numpy()\n",
    "            img_np = img[0].cpu().numpy().transpose(1,2,0)\n",
    "            if img_np.max()>1: img_np/=255\n",
    "            cam = cv2.resize(cam, img_np.shape[:2][::-1])\n",
    "            overlay = 0.5*img_np + 0.5*plt.cm.jet(cam)[:,:,:3]\n",
    "            plt.subplot(2,len(factors),i+1)\n",
    "            plt.imshow(overlay)\n",
    "            plt.title(f\"{f}x\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(2,len(factors),len(factors)+i+1)\n",
    "            a,b = preds[i][0]\n",
    "            plt.bar([\"Î±\",\"Î²\"], [a,b])\n",
    "            plt.ylim(0,1)\n",
    "\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_radial(self, res, title):\n",
    "        radii = res[\"radii\"]\n",
    "        preds = res[\"preds\"].squeeze()\n",
    "\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(radii, preds[:,0], \"-o\", label=\"Î±\")\n",
    "        plt.plot(radii, preds[:,1], \"-o\", label=\"Î²\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Radius Mask (px)\")\n",
    "        plt.ylabel(\"Normalized Prediction\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(cfg)\n",
    "\n",
    "ckpt_imgnet = find_checkpoint(cfg[\"ckpt_imagenet\"])\n",
    "ckpt_synth  = find_checkpoint(cfg[\"ckpt_synth\"])\n",
    "\n",
    "print(\"Imagenet ckpt:\", ckpt_imgnet)\n",
    "print(\"Synthetic ckpt:\", ckpt_synth)\n",
    "\n",
    "model_imgnet = load_model(ckpt_imgnet)\n",
    "model_synth  = load_model(ckpt_synth)\n",
    "\n",
    "tester_imgnet = StressTester(model_imgnet, device)\n",
    "tester_synth  = StressTester(model_synth, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(len(dataset), min(3,len(dataset)), replace=False)\n",
    "\n",
    "for idx in indices:\n",
    "    img, label = dataset[idx]\n",
    "    img_batch = img.unsqueeze(0)\n",
    "\n",
    "    print(f\"\\n===============================\")\n",
    "    print(f\"Testing Image {idx}\")\n",
    "    print(\"===============================\")\n",
    "\n",
    "    # Zoom\n",
    "    zoom_imgnet = tester_imgnet.run_zoom(img_batch)\n",
    "    zoom_synth  = tester_synth.run_zoom(img_batch)\n",
    "\n",
    "    # Radial\n",
    "    radial_imgnet = tester_imgnet.run_radial(img_batch)\n",
    "    radial_synth  = tester_synth.run_radial(img_batch)\n",
    "\n",
    "    # Plot\n",
    "    tester_imgnet.plot_zoom(img_batch, zoom_imgnet,\n",
    "        f\"Zoom Test â€” ImageNet â€” {cfg['name']} â€” idx {idx}\")\n",
    "    tester_synth.plot_zoom(img_batch, zoom_synth,\n",
    "        f\"Zoom Test â€” Synthetic â€” {cfg['name']} â€” idx {idx}\")\n",
    "\n",
    "    tester_imgnet.plot_radial(radial_imgnet,\n",
    "        f\"Radial Mask Test â€” ImageNet â€” {cfg['name']} â€” idx {idx}\")\n",
    "    tester_synth.plot_radial(radial_synth,\n",
    "        f\"Radial Mask Test â€” Synthetic â€” {cfg['name']} â€” idx {idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
